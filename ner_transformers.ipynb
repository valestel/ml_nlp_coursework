{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to explore named entity recognition pipeline in Transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from transformers import pipeline\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "# load the pipeline\n",
    "ner = pipeline('ner', aggregation_strategy='simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘ner_train.pkl’ already there; not retrieving.\n",
      "\n",
      "File ‘ner_test.pkl’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download CoNLL 2003 datasets\n",
    "!wget -nc https://lazyprogrammer.me/course_files/nlp/ner_train.pkl\n",
    "!wget -nc https://lazyprogrammer.me/course_files/nlp/ner_test.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test corpora\n",
    "with open('ner_train.pkl', 'rb') as f:\n",
    "    corpus_train = pickle.load(f)\n",
    "    \n",
    "with open('ner_test.pkl', 'rb') as f:\n",
    "    corpus_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CRICKET', 'O'),\n",
       " ('-', 'O'),\n",
       " ('LEICESTERSHIRE', 'B-ORG'),\n",
       " ('TAKE', 'O'),\n",
       " ('OVER', 'O'),\n",
       " ('AT', 'O'),\n",
       " ('TOP', 'O'),\n",
       " ('AFTER', 'O'),\n",
       " ('INNINGS', 'O'),\n",
       " ('VICTORY', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split tags and words\n",
    "inputs = []\n",
    "targets = []\n",
    "\n",
    "for sentence_tag_pairs in corpus_test:\n",
    "    tokens = []\n",
    "    target = []\n",
    "    for token, tag in sentence_tag_pairs:\n",
    "        tokens.append(token)\n",
    "        target.append(tag)\n",
    "    inputs.append(tokens)\n",
    "    targets.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Essex',\n",
       " ',',\n",
       " 'however',\n",
       " ',',\n",
       " 'look',\n",
       " 'certain',\n",
       " 'to',\n",
       " 'regain',\n",
       " 'their',\n",
       " 'top',\n",
       " 'spot',\n",
       " 'after',\n",
       " 'Nasser',\n",
       " 'Hussain',\n",
       " 'and',\n",
       " 'Peter',\n",
       " 'Such',\n",
       " 'gave',\n",
       " 'them',\n",
       " 'a',\n",
       " 'firm',\n",
       " 'grip',\n",
       " 'on',\n",
       " 'their',\n",
       " 'match',\n",
       " 'against',\n",
       " 'Yorkshire',\n",
       " 'at',\n",
       " 'Headingley',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use detokenizer to make the whole sentence\n",
    "detokenizer = TreebankWordDetokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Essex, however, look certain to regain their top spot after Nasser Hussain and Peter Such gave them a firm grip on their match against Yorkshire at Headingley.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detokenizer.detokenize(inputs[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'I-PER',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'I-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'ORG',\n",
       "  'score': 0.99925417,\n",
       "  'word': 'Essex',\n",
       "  'start': 0,\n",
       "  'end': 5},\n",
       " {'entity_group': 'PER',\n",
       "  'score': 0.9996957,\n",
       "  'word': 'Nasser Hussain',\n",
       "  'start': 60,\n",
       "  'end': 74},\n",
       " {'entity_group': 'PER',\n",
       "  'score': 0.999509,\n",
       "  'word': 'Peter Such',\n",
       "  'start': 79,\n",
       "  'end': 89},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9989281,\n",
       "  'word': 'Yorkshire',\n",
       "  'start': 135,\n",
       "  'end': 144},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.99204224,\n",
       "  'word': 'Headingley',\n",
       "  'start': 148,\n",
       "  'end': 158}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the pipeline\n",
    "ner(detokenizer.detokenize(inputs[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to map pipeline result to list of tags for later performance assessment\n",
    "def compute_prediction(tokens, input_, ner_result):\n",
    "    # tokens is the original tokenized sentence, input_ is the detokenized string\n",
    "    predicted_tags = []\n",
    "    # keep track of state\n",
    "    state = 'O'\n",
    "    current_index = 0\n",
    "    for token in tokens:\n",
    "        # find the token in the input_ (should be at or near the start)\n",
    "        index = input_.find(token)\n",
    "        assert(index >= 0)\n",
    "        current_index += index\n",
    "        # check if this index belongs to an entity and assign label\n",
    "        tag = 'O'\n",
    "        for entity in ner_result:\n",
    "            if current_index >= entity['start'] and current_index < entity['end']:\n",
    "                # this token belongs to an entity\n",
    "                if state == 'O':\n",
    "                    state = 'B'\n",
    "                else:\n",
    "                    state = 'I'\n",
    "                tag = f\"{state}-{entity['entity_group']}\"\n",
    "                break\n",
    "        if tag == \"O\":\n",
    "            # reset the state\n",
    "            state = \"O\"\n",
    "        predicted_tags.append(tag)\n",
    "        # remove the token from input_\n",
    "        input_ = input_[index + len(token):]\n",
    "        # update current_index\n",
    "        current_index += len(token)\n",
    "    # sanity check    \n",
    "    assert(len(predicted_tags) == len(tokens))\n",
    "    return predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = detokenizer.detokenize(inputs[5])\n",
    "ner_result = ner(input_)\n",
    "pred_tags = compute_prediction(inputs[5], input_, ner_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(targets[5], pred_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-ORG B-ORG\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-PER B-PER\n",
      "I-PER I-PER\n",
      "O O\n",
      "B-PER B-PER\n",
      "I-PER I-PER\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "O O\n",
      "B-ORG B-ORG\n",
      "O O\n",
      "B-LOC B-LOC\n",
      "O O\n"
     ]
    }
   ],
   "source": [
    "for target, prediction in zip(targets[5], pred_tags):\n",
    "    print(target, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get detokenized inputs to pass into the model\n",
    "detok_inputs = []\n",
    "for tokens in inputs:\n",
    "    text = detokenizer.detokenize(tokens)\n",
    "    detok_inputs.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_results = ner(detok_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for tokens, text, ner_result in zip(inputs, detok_inputs, ner_results):\n",
    "    pred = compute_prediction(tokens, text, ner_result)\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(list_of_lists):\n",
    "    return [val for sublist in list_of_lists for val in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten targets and predictions to calculate accuracy and F1\n",
    "flat_predictions = flatten(predictions)\n",
    "flat_targets = flatten(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9916563354782848"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(flat_targets, flat_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95403328229255"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(flat_targets, flat_predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
